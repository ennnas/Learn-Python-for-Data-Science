{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from movielens dataset with a rating higher than 4.0\n",
    "data = fetch_movielens(min_rating=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repr(data[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "model = LightFM(loss=\"warp\")\n",
    "# train the model\n",
    "model.fit(data[\"train\"], epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, user_ids):\n",
    "\n",
    "    #number of users and movies in training data\n",
    "    n_users, n_items = data['train'].shape\n",
    "\n",
    "    #generate recommendations for each user we input\n",
    "    for user_id in user_ids:\n",
    "\n",
    "        #movies they already like\n",
    "        # CSR --> https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "\n",
    "        #movies our model predicts they will like\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        #rank them in order of most liked to least\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "\n",
    "        #print out the results\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "\n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "\n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_recommendation(model, data, [3, 5, 24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "### new dataset with comparison between three different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jester Online Joke Recommender System\n",
    "jokes = [i for i in range(100)]\n",
    "names = [\"#Jokes\"] + jokes\n",
    "df = pd.read_excel(\"jester.xls\",header=None, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all negative values with -1\n",
    "df[ df < 0] = -1\n",
    "# replace all NaN=99.0 values with 0\n",
    "df[ df == 99.0] = 0\n",
    "# replace all positive values with +1\n",
    "df[ df > 0] = +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize first 5 users raitings\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "train = csr_matrix(df.drop(labels=\"#Jokes\",axis=1)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.SparseDataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = train_set.to_coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {\"Wrap\": LightFM(loss=\"warp\"), \"Logistic\": LightFM(loss=\"logistic\"), \"Bpr\": LightFM(loss=\"bpr\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models.keys():\n",
    "    models[model_name].fit(train_set, epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user x the top jokes will be\n",
    "x = 300\n",
    "scores = {}\n",
    "for model_name in models.keys():\n",
    "    scores[model_name] = models[model_name].predict([x], np.arange(100))\n",
    "    top3 = np.argsort(-scores[model_name])[:3]\n",
    "    print(\"Model: {:10s} Top-3 Jokes:{}\".format(model_name,top3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
